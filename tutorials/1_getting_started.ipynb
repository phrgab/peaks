{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "`peaks` is a collection of analysis tools for the loading, processing and display of spectroscopic and diffraction data, with a core focus on tools for angle-resolved photoemission, LEED, RHEED, and some other related techniques. It also includes various functions for efficient log keeping. \n",
    "\n",
    ":::{tip}\n",
    "`peaks` builds heavily on :class:`xarray`. The user is *strongly* recommended to consult the extensive documentation and tutorials available on the [xarray website](https://docs.xarray.dev/en/stable/). \n",
    "::: \n",
    "\n",
    "These user guides give a brief introduction to the use of `peaks`. More extensive documentation and examples can be accessed via the docstrings of the relevant functions. \n",
    "\n",
    ":::{tip}\n",
    "The docstrings of the relevant `peaks` functions can be viewed in the [package documentation](https://research.st-andrews.ac.uk/kinggroup/peaks/_apidoc/peaks.html), or accessed in the notebook by calling help on the relevant function, e.g.:\n",
    "```python\n",
    "help(pks.load)\n",
    "```\n",
    "or using the `?` shortcut:\n",
    "```\n",
    "pks.load?\n",
    "```\n",
    "In Jupyter Lab, pressing `TAB` will bring some auto-complete options, while `SHIFT`-`TAB` can be used to show the expected function arguments.\n",
    "\n",
    "A quick look at the source code can be achieved using `??`, e.g.:\n",
    "```\n",
    "pks.load??\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Importing `peaks`\n",
    "The recommended way to import peaks is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import peaks as pks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "This loads a set of core functions (mostly from `peaks.core` and `peaks.utils`) into the `pks` namespace, and adds several functions as accessors to the relevant :class:`xarray` objects.\n",
    "\n",
    "It is often useful to also import a number of other related packages. In addition, it can be useful to set some [global options](https://docs.xarray.dev/en/stable/generated/xarray.set_options.html#xarray.set_options) for [`xarray`](xarray) and e.g. [`matplotlib`](matplotlib). A complete import may therefore look like, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import peaks as pks\n",
    "import os\n",
    "\n",
    "# Set default options\n",
    "xr.set_options(cmap_sequential='Purples', keep_attrs=True)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "You may find it useful to include the above in an IPython startup script, so that this is pre-loaded each time you start a new notebook (or any IPython session) from this environment. \n",
    "\n",
    "Locate the IPython Profile Directory:\n",
    "```python\n",
    "import IPython\n",
    "IPython.paths.locate_profile()\n",
    "```\n",
    "\n",
    "This will give you the path to the default profile directory, typically something like `/home/username/.ipython/profile_default`. Within the `starup` directory of the above profile directory, place one or more python files defining the scripts you want to run.  These are executed in alphabetical order, so if you have multiple scripts, you can control the order of execution by naming them accordingly, like `00-script.py`, `01-script.py`, ...\n",
    "\n",
    "E.g. to reproduce the above, make a file e.g. `00-startup.py` as:\n",
    "```python\n",
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import peaks as pks\n",
    "import os\n",
    "\n",
    "# Set default xarray options\n",
    "xr.set_options(cmap_sequential='Purples', keep_attrs=True)\n",
    "\n",
    "# Get the IPython interactive shell\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "\n",
    "# Run the notebook magic commands\n",
    "ipython.run_line_magic('matplotlib', 'inline')\n",
    "ipython.run_line_magic('config', \"InlineBackend.figure_format='retina'\")\n",
    "```\n",
    "Note the different way that the jupyter magics must be run here. This should now be run the next time you launch an IPython session.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    ":::{attention}\n",
    "For this tutorial, a few sample data sets will be downloaded to a temporary folder, and we will use the class to access the relevant file path of the temporary folder. Make sure to clean up the temporary folder when finished following the instructions below.\n",
    "\n",
    "In the following, `sample_data.fpath` provides the file path of the temporary folder where the files have been placed. When loading your own data, replace `sample_data.fpath` in the following with a string providing the folder path where your data is located.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the example data\n",
    "from peaks.core.utils.sample_data import get_tutorial1_data\n",
    "sample_data = get_tutorial1_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Load data using the `load` function. `peaks` attempts to identify the relevant data source (beamline, lab system, etc.) automatically, although it can be manually specified with the `loc=` option. \n",
    "\n",
    ":::{tip}\n",
    "To see available `loc` options, call:\n",
    "\n",
    "```python\n",
    "pks.locs()\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "A single file can be loaded specifying the full path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1 = pks.load(os.path.join(sample_data.fpath,'i05-59819.nxs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Setting default fileIO options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "To ease loading of data and provide a cleaner syntax, the file path (optionally including the first part of the file name) and optionally also the file extension and location identifier can be specified using `peaks` options, `pks.opts`. To show currently set options for FileIO: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pks.opts.FileIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "`FileIO` are one of the option sets for `peaks`. To see current settings of other options, call `pks.opts`.\n",
    ":::\n",
    "\n",
    "These can be set as persistant values for the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pks.opts.FileIO.path = os.path.join(sample_data.fpath,'i05-59')\n",
    "pks.opts.FileIO.ext = 'nxs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "The file can then be loaded using any identifier (string or object that can be parsed as a string) that would uniuqely identify the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1=pks.load(819)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Standard wildcards are supported:\n",
    "\n",
    "| Wildcard | Description | \n",
    "|----------|-------------|\n",
    "| `*`      | Matches any number of characters (except path separator `/`) |,\n",
    "| `?`      | Matches a single character (except `/`)                      |,\n",
    "| `[...]`  | Matches any one character inside the brackets                |,\n",
    "| `[!...]` | Matches any one character **not** inside the brackets        |,\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1=pks.load('8?9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "You can pass a list of options to allow e.g. automatic loading of multiple file types, and set and reset individual entries as, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ext and loc\n",
    "pks.opts.FileIO.ext = ['nxs','ibw']\n",
    "pks.opts.FileIO.loc = 'MAXIV_Bloch_A'\n",
    "\n",
    "# Reset the path\n",
    "del pks.opts.FileIO.path\n",
    "\n",
    "# Reset all options within FileIO\n",
    "pks.opts.FileIO.reset()\n",
    "\n",
    "# Set multiple options at once\n",
    "pks.opts.FileIO.set(ext='nxs', loc='Diamond_I05_ARPES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pks.opts.FileIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "`FileIO` is part of a more general options class, accessed via `pks.opts`, which can also be used as a context manager to temporarily set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset all existing file options\n",
    "pks.opts.FileIO.reset()\n",
    "print(f\"Before:\\n{pks.opts.FileIO}\")\n",
    "\n",
    "with pks.opts as opts:\n",
    "    # Temporarily set the relevant options\n",
    "    opts.FileIO.path = os.path.join(sample_data.fpath,'i05-59')\n",
    "    opts.FileIO.ext = 'nxs'\n",
    "    disp1 = pks.load(819)\n",
    "\n",
    "# Now display the options, which should have no FileIO optios\n",
    "print(f\"After:\\n{pks.opts.FileIO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Multiple scans can be loaded at once passing a list of full filenames or filename fragments. A list of names can be passed as scan identifiers. If not defined, these are automatically parsed from the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default file options\n",
    "pks.opts.FileIO.path = os.path.join(sample_data.fpath,'i05-59')\n",
    "pks.opts.FileIO.ext = 'nxs'\n",
    "\n",
    "multiple_disp = pks.load([819,853], names=['disp1','gold'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Data format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "The base data format of most loaded data is an `xarray:DataArray`. This can be inspected by typing the variable in the interactive shell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "The co-ordinates give the dimension scales, while the raw data itself can be accessed via the accesssor `.data`. Where possible, `peaks` attempts to treat the data (and also associated metadata) keeping track of the units. Therefore the data will typically be composed of a :class:`xarray.DataArray` wrapping a :class:`pint` array, which is itself wrapping a :class:`numpy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(disp1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.data.magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.data.units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "The methods of :class:`pint-xarray` can be used to perform unit-aware selections on the resulting :class:`xarray.DataArray` via the `.pint` accessor. The data can also be converted back into a classic :class:`numpy`-backed :class:`xarray.DataArray` using the `.dequantify()` method. See the [documentation](https://pint-xarray.readthedocs.io/en/stable/) and this [blog](https://xarray.dev/blog/introducing-pint-xarray).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Lazy loading of large data\n",
    "If the data being loaded is large, it may be loaded lazily into a [`dask`](https://www.dask.org) format. This allows the loading of files that are too large to fit in memory, but also can lead to some advantages for paralellisation of processing etc. even on smaller datasets. If a file is loaded with a dask-based array, subsequent operations are also lazy until `.compute()` is called, allowing developing sophisticated pipelines. See the [`xarray` user guide](https://docs.xarray.dev/en/latest/user-guide/dask.html). \n",
    "\n",
    "The underlying array can also be loaded into memory using `.persist()`. If the array fits in memory, this will substantially speed up subsequent calculations and plotting (otherwise the data needs to be effectively loaded from disk each time). Alternatively, you can pass `lazy=False` in the data loading to load directly as a standary `numpy`-based array. Be careful, however, if the data is very large as this may lead to a crash.\n",
    "\n",
    ":::{note}\n",
    "Not all file loaders support lazy loading. If the underlying data type is in a suitable format however (e.g. HDF5, Zarr store etc.), then the data will be automatically loaded in a lazy manner if the underlying array size is larger than the threshold set in `pks.opts.FileIO.lazy_size`. This is 1 GB by default, but can be set by the user. Manual lazy loading can be triggered by passing a `Boolean` to the `pks.load()` method.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with pks.opts as opts:\n",
    "    opts.FileIO.lazy_size = int(1e8)\n",
    "    FS1 = pks.load(818)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Now a view of the loaded `xr.DataArray` now shows the chunked structure associated with a :class:`dask` array\n",
    "\n",
    ":::{tip}\n",
    "Even if a loader does not support lazy loading, the loaded data can be converted to a :class:`dask`-backed array using the `.chunk()` method [see `xarray` documentation](https://docs.xarray.dev/en/stable/user-guide/dask.html).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "The usual `xarray` commands (see later) still work, and will typically be evaluated lazily, making them extremely quick, but note no computation has yet been performed. The actual computation only be performed when required, and can be triggered by calling `.compute()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time FS1.sum('eV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time FS1.sum('eV').compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Some function calls will automatically trigger the computation where required, e.g. for plotting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS1.sum('eV').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### Grouping scans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "If multiple scans are loaded simultaneously, these are loaded into a :class:`xarray.DataTree` structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "This can be considered as a tree-like structure, where the stored data are the leaves of the tree. A quick view of the tree structure (and included scans) can be accessed via the method `.view()`. This prints a tree structure, where items containing data are coloured in green. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Or a more detailed view via a simple `print()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiple_disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "The scan data can then be accessed using dictionary methods or an object-oriented approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.disp1.data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    ":::{attention}\n",
    "Note, the :class:`xarray.DataTree` structure requires data in the leaves of the tree to be in a :class:`xarray.Dataset` format, rather than a :class:`xarray.DataArray`. Unless the data is already in :class:`xarray.Dataset` form, `peaks` convention is to convert the :class:`xarray.DataArray` to a :class:`xarray.Dataset` with a single data variable `data`. Note the additional `.data` used above the access the underlying :class:`xarray.DataArray`. This :class:`xarray.DataArray` now has the name `data` rather than the default scan name. The original scan (file) name is still accessible via the [metadata](#metadata)\n",
    "```python\n",
    "multiple_disp.disp.scan.name\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "#### Extending tree structure\n",
    "A new scan group (branch of the :class:`xarray.DataTree` can be added to the tree via the helper method `.add_scan_group()`, optionally specifying a name for the group. If no name is specified a default `scan_group_#` name will be used where # is a number to make it unique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "multiple_disp = pks.load([819,853], names=['disp1','gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.add_scan_group('FS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "Add a file to the :class:`xarray.DataTree` by passing an already loaded :class:`xarray.DataArray`, optionally providing a name for the entry in the :class:`xarray.DataTree`. Note that this is being inserted into the new scan group just created. `peaks` convention is that the :class:`xarray.DataTree` should be hollow, i.e. that data can only be added as *leafs* and not on *branches*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp['FS'].add(FS1, name='FS1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "The contents of another :class:`xarray.DataTree` can be added to the original tree. Here, each scan of the new tree is added at the root level of the `multiple_disp` tree, specified by passing `add_at_root=True`. Note, this is inserted at the root level of the tree that you call `.add()` on; it may be that that actually has a parent still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with specific names for the scans\n",
    "dt2 = pks.load([819,853], names=['disp_copy','gold_copy'])\n",
    "# Insert these scans all into the original DataTree\n",
    "multiple_disp.add(dt2, add_at_root=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "Alternatively, they can be added as a new scan block, either with a specified name, or with an automatically generated name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt3 = pks.load([819,853])\n",
    "multiple_disp.add(dt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "Data can also be loaded directly into the :class:`xarray.DataTree` by passing the arguments that are passed to :class:`peaks.load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.add([819,853], name='loaded_directly', names=['disp_copy2','gold_copy2'], lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "Individual entries or sections of the tree can be removed by a simple `del`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "del multiple_disp['scan_group_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    ":::{attention}\n",
    "Apart from working with hollow trees, `peaks` does not enforce a particular data structure for the :class:`xarray.DataTree` and it is at the user's discretion how to best organise their data this way. Recommended practice is to use this as a broad structure to facilitate grouping data together and for batch processing. It also provides a convenient method for saving groups of data following data processing. But the user should take care to ensure a transparent record of what processing has occured, and the underlying :class:`xarray.DataArray` (or sometimes :class:`xarray.Dataset`) remains the fundamental data unit. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "The relevant metadata for the data is stored in the :class:`xarray.Dataarray` attributes. \n",
    ":::{tip}\n",
    "While this can be modified using standard :class:`xarray` methods, in general the user should not modify the metadata directly, but rather using the provided methods described below. This has several advantages:\n",
    "- it will ensure that the metadata complies with the expected `peaks` metadata structure\n",
    "- it adds a transpart record to the analysis history when metadata is manually changed (see [user guide on analysis history](./4_analysis_history.ipynb)).\n",
    "- it provides simple methods for updating metadata across multiple scans when stored within :class:`xarray.DataTree`'s.\n",
    ":::\n",
    "\n",
    "To show the complete set of the current metadata, simply call the `.metadata` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "The relevant keys for the metadata entries can be returned with `.keys()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "Metadata can be shown for individual subgroups using a dot notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata.photon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "and set using a simple assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata.photon.hv = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata.photon.hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata.photon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "Units are maintained where already existing, or can be set explicitly by passing a :class:`pint.Quantity` where the unit registry is available in the `peaks` namespace as `pks.ureg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata.photon.exit_slit = 10 * pks.ureg('um')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata.photon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "Metadata can also be updated by passing a dictionary which respects the structure of the metadata groups starting from the level where called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata.analyser.deflector({'parallel': {'local_name': 'deflector_1'}, 'perp': {'local_name': 'deflector_2'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "Special methods for setting normal emission metadata are discussed in the [data processing guide](./3_data_processing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "### Batch updating metadata for a DataTree\n",
    "For data stored within a :class:`xarray.DataTree` structure, you can apply the `.metadata` method to all scans in the subtree below the passed tree node. This requires the metadata to be updated to be passed in a dictionary with the same nested structure as the relevant metadata structure, and requires this structure to be the same for all data within the tree. Either a single dictionary can be passed, or keyword arguments can be used to specify the metadata group to be updated. For example, for updating a single attribute of `scan` metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.disp1.data.metadata.scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "Updating with keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.metadata(scan={'scan_command': 'Example of updating the metadata'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.disp1.data.metadata.scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "Or updating with a single `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.metadata({'scan': {'scan_command': 'Example of updating the metadata again'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.disp1.data.metadata.scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "### Setting manipulator normal emissions\n",
    "\n",
    "Additional helper methods exist for setting normal emission values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = FS1.MDC(105.05,0.05).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough estimate of normal emission\n",
    "FS.plot()\n",
    "plt.axvline(0.05)\n",
    "plt.axhline(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "To set the relevant axis reference values, we can use the `.metadata.set_normal_emission()` method, passing our determined values as either a dictionary or with keyword arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS1.metadata.set_normal_emission(polar=1.5, theta_par=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "Now reference values are set for the relevant polar and tilt axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS1.metadata.manipulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "To set normal emission values of a scan (or an entire :class:`xarray.DataTree`) to be like another scan, use the `set_normal_emission_like` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata.set_normal_emission_like(FS1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.metadata.manipulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "### Analysis history\n",
    "To enhance the reproducibility and data provenance for data analysed using `peaks`, we attempt to keep track of data operations performed using in-built `peaks` functions (including the name of the calling function), and store these in a JSON-type record within the data attributes of the :class:`xarray.DataArray`, under the entry `analysis_history`. While a well-organised Jupyter notenbook is a good start, the user has to be careful to only execute cells in order, and a typical analysis workflow may involve loading and processing some data and saving an intermediate step, before further post-processing in another notebook, necessating a richer storing of data analysis history. Saving and loading using in-built peaks methods will attempt to keep a persistent data analysis record in tact. The analysis history can also show up where some additional methods (e.g. automatic Fermi level estimation) have been called as part of the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp2 = pks.load(819)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "An initial history record is made upon loading, which can be accessed via the `.history()` accessor. This attempts to display the history in a formatted table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp2.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "`peaks` functions typically add brief history records, including when metadata is updated using the methods discussed [above](#metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp2.metadata.scan.name = 'test example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp2.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "Some records cam get a little complicated, so a single record can be printed in a clearer format by calling the history accessor with an index of the record to display (defaults to the last record if nothing is passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp2.history(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "The corresponding dictionary can be returned, rather than just printed, if calling with the `.get(index)` method, or a list of all entries can be returned if calling with no specified index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp2.history.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "#### Saving analysis history\n",
    "A json string of the entire analysis history record can be returned using the `history.json` method, and saved using `history.save()`. It can then be opened in the standard way, or e.g. viewed in a web browser or other software. The metadata record is also saved as part of the data if saving using the :class:`peaks` :class:`peaks.save` and :class:`peaks.load` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history metadata only\n",
    "disp2.history.save('saving_analysis_metadata.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121",
   "metadata": {},
   "source": [
    "#### Manually adding analysis history\n",
    "\n",
    "Most `peaks`-specific functions aim to add a related history record, which is one reason to use these functions even where they are otherwise only thin wrappers around e.g. existing :class:`xarray functions`. Operating on a :class:`xarray.DataArray` with e.g. a built in :class:`xarray` method or other non `peaks`-specific function will not lead to the analysis record being updated. In such cases, you should manaully update the analysis record using `.history.add()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually change one of the dispersions\n",
    "disp2 *= 10\n",
    "\n",
    "# Add the history record\n",
    "disp2.history.add('Data intensity multiplied by 10', fn_name='Manual record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp2.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "This methodology can be used within a custom function, where `peaks` will attempt to also capture the name of the calling function. The data can either be updated in place (behaviour when calling with the `.add` accessor) or a copy of the data with modified history metadata can be returned using the `.assign()` accessor, to aid in chaining methods together (similar to the :class:`xarray.DataArray.assign_attrs` and :class:`xarray.DataArray.assign_coords` methods).\n",
    "\n",
    ":::{warning}\n",
    "It is easy to accidentally update the analysis history of the underlying :class:`xarray.DataArray` that was passed to the function. This should be carefully checked to ensure the desired operation.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_one(data):\n",
    "    data = data.history.assign('Added one to the original data')\n",
    "    return data + 1*pks.ureg('count/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3 = add_one(disp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "For simple cases like the above, where e.g. no parameters to pass to the history string need to be determined during the function execution, a decorator method can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peaks.core.metadata.history import update_history_decorator\n",
    "\n",
    "@update_history_decorator('Added two to the data')\n",
    "def add_two(data):\n",
    "    return data + 2*pks.ureg('count/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3 = add_two(disp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132",
   "metadata": {},
   "source": [
    "## Saving data\n",
    "Data can be saved using the `.save()` accessor. A single :class:`xarray.DataArray` or :class:`xarray.Dataset` is saved in a netCDF file (extension `.nc`) and a :class:`xarray.DataTree` is stored in a Zarr file (extension `.zarr`). Any metadata attributes stored using `peaks` methods should be serialised and re-openeded correctly, at least if using the same version of `peaks`. If other metadata has been stored in the attributes, this may not be parsed properly depending on the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1.save('disp1.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_disp.save('dt_example.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135",
   "metadata": {},
   "source": [
    "These can then be loaded again using the regular :class:`peaks.load` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_disp1 = pks.load('disp1.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dt = pks.load('dt_example.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "Run the following cell to clean up the temporary files downloaded for use during this tutorial. This would not be required in normal usage with your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140",
   "metadata": {},
   "source": [
    "Run the following cell to clean up the files saved during this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "for file_path in [Path(\"disp1.nc\"),Path(\"dt_example.zarr\")]:\n",
    "    if file_path.exists() and file_path.is_dir():\n",
    "        shutil.rmtree(file_path)\n",
    "    elif file_path.exists():\n",
    "        file_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peaks-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
